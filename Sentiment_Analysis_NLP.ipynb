{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "41f4ce18-7992-4826-869e-1771026c3855",
      "metadata": {
        "id": "41f4ce18-7992-4826-869e-1771026c3855"
      },
      "source": [
        "# Sentiment Analysis using NLP and Library TextBlob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ffe0f3-2b57-4336-a539-98c3a452145c",
      "metadata": {
        "id": "e5ffe0f3-2b57-4336-a539-98c3a452145c"
      },
      "source": [
        "# 1. Import required libraries\n",
        "- nltk: A Python library for NLP tasks like tokenization, stemming, and lemmatization.\n",
        "- spacy: A library for advanced NLP tasks such as named entity recognition (NER).\n",
        "- textblob: Used for sentiment analysis and text processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "841cd7e1-7cd3-4997-bf40-cc607d85ed47",
      "metadata": {
        "id": "841cd7e1-7cd3-4997-bf40-cc607d85ed47"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import spacy\n",
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc6eb641-fcf0-49f8-a98a-731fc03f773c",
      "metadata": {
        "id": "fc6eb641-fcf0-49f8-a98a-731fc03f773c"
      },
      "source": [
        "# 2. Downloading NLTK Datasets\n",
        "- punkt: A tokenizer model used for splitting sentences and words.\n",
        "- stopwords: A dataset of common stopwords in English (like \"is\", \"and\", \"the\").\n",
        "- wordnet: A lexical database for lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "392eb8ce-e7ae-4dd9-bdfc-eeebfccee639",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "392eb8ce-e7ae-4dd9-bdfc-eeebfccee639",
        "outputId": "1453678e-cf5c-4258-9096-909abc0a258f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59b33251-5863-4b70-94ef-df25f858b146",
      "metadata": {
        "id": "59b33251-5863-4b70-94ef-df25f858b146"
      },
      "source": [
        "# 3. Defining Sample Text\n",
        "- A multi-sentence text is provided as input for processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "463f054d-1b9a-479c-839f-7aa6616418b8",
      "metadata": {
        "id": "463f054d-1b9a-479c-839f-7aa6616418b8"
      },
      "outputs": [],
      "source": [
        "# Sample text\n",
        "text = \"\"\"Natural Language Processing (NLP) is a fascinating field of artificial intelligence.\n",
        "It focuses on making machines understand human language. NLP powers applications like chatbots,\n",
        "language translation tools, and voice assistants.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7ab3697-597a-4eb7-9577-2ce4e4c68c42",
      "metadata": {
        "id": "b7ab3697-597a-4eb7-9577-2ce4e4c68c42"
      },
      "source": [
        "# 4. Sentence Tokenization\n",
        "#### TASK 1: TOKENIZATION\n",
        "- Tokenization: Breaking text into smaller units like words or sentences.\n",
        "- Sentence Tokenization splits the text into sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ee392f84-9fe4-401d-9312-7e0cdee1d754",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee392f84-9fe4-401d-9312-7e0cdee1d754",
        "outputId": "27cb03b7-f101-4815-8662-46b19f2179af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenization:\n",
            "['Natural Language Processing (NLP) is a fascinating field of artificial intelligence.', 'It focuses on making machines understand human language.', 'NLP powers applications like chatbots, \\nlanguage translation tools, and voice assistants.']\n"
          ]
        }
      ],
      "source": [
        "print(\"Sentence Tokenization:\")\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2e5b37-b779-4abe-825a-111b540888e9",
      "metadata": {
        "id": "af2e5b37-b779-4abe-825a-111b540888e9"
      },
      "source": [
        "# 5. Word Tokenization\n",
        "#### TASK 2: split Sentence\n",
        "- Word Tokenization splits the text into individual words or tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "31a7d5be-2966-4776-8ae7-681e583bafbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31a7d5be-2966-4776-8ae7-681e583bafbd",
        "outputId": "15028de4-d522-45a5-a46e-615cb8fb1a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Tokenization:\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', '.', 'It', 'focuses', 'on', 'making', 'machines', 'understand', 'human', 'language', '.', 'NLP', 'powers', 'applications', 'like', 'chatbots', ',', 'language', 'translation', 'tools', ',', 'and', 'voice', 'assistants', '.']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nWord Tokenization:\")\n",
        "words = word_tokenize(text)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3253034-be68-4659-a383-8240fb302ad4",
      "metadata": {
        "id": "c3253034-be68-4659-a383-8240fb302ad4"
      },
      "source": [
        "# 6. Stopword Removal\n",
        "#### TASK 3: REMOVING STOPWORDS\n",
        "- Stopword Removal: Removing frequently occurring words that are not meaningful.\n",
        "- Stopwords are common words (e.g., \"is\", \"and\", \"the\") that are removed as they don't add significant meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5e8da233-b380-4c4a-a9c7-0e2a5942721f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e8da233-b380-4c4a-a9c7-0e2a5942721f",
        "outputId": "d722433d-3186-4e66-f1ed-5cd9ed9417fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Filtered Words (without Stopwords):\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'fascinating', 'field', 'artificial', 'intelligence', '.', 'focuses', 'making', 'machines', 'understand', 'human', 'language', '.', 'NLP', 'powers', 'applications', 'like', 'chatbots', ',', 'language', 'translation', 'tools', ',', 'voice', 'assistants', '.']\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "print(\"\\nFiltered Words (without Stopwords):\")\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea3b02f-9b8d-4e2d-b52b-429bdbfc3b2d",
      "metadata": {
        "id": "1ea3b02f-9b8d-4e2d-b52b-429bdbfc3b2d"
      },
      "source": [
        "# 7. Stemming\n",
        "#### TASK 3: reduces words\n",
        "- Stemming reduces words to their root form. For example:\n",
        "   - \"fascinating\" → \"fascin\"\n",
        "   - \"processing\" → \"process\"\n",
        "- Stemming is faster but less accurate (e.g., \"studies\" → \"studi\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "81b941cf-fdb1-4d91-8a86-cc3f2c512e69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81b941cf-fdb1-4d91-8a86-cc3f2c512e69",
        "outputId": "fad5dd13-7d0d-4937-d23d-befc7a15f026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemmed Words:\n",
            "['natur', 'languag', 'process', '(', 'nlp', ')', 'fascin', 'field', 'artifici', 'intellig', '.', 'focus', 'make', 'machin', 'understand', 'human', 'languag', '.', 'nlp', 'power', 'applic', 'like', 'chatbot', ',', 'languag', 'translat', 'tool', ',', 'voic', 'assist', '.']\n"
          ]
        }
      ],
      "source": [
        "ps = PorterStemmer()\n",
        "stemmed_words = [ps.stem(word) for word in filtered_words]\n",
        "print(\"\\nStemmed Words:\")\n",
        "print(stemmed_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ea40b0-d771-4e21-b913-fada75f4f57d",
      "metadata": {
        "id": "04ea40b0-d771-4e21-b913-fada75f4f57d"
      },
      "source": [
        "# 8. Lemmatization\n",
        "#### TASK 4: converts words base form\n",
        "- Lemmatization converts words to their dictionary base form (considering context).\n",
        "  - Example: \"running\" → \"run\", \"better\" → \"good\".\n",
        "- Lemmatization is slower but context-aware (e.g., \"studies\" → \"study\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e385710c-2a6a-4451-9729-1211a7ef4e7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e385710c-2a6a-4451-9729-1211a7ef4e7b",
        "outputId": "4fa17e01-ba68-4088-b5d2-66fb0fa78f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lemmatized Words:\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'fascinating', 'field', 'artificial', 'intelligence', '.', 'focus', 'making', 'machine', 'understand', 'human', 'language', '.', 'NLP', 'power', 'application', 'like', 'chatbots', ',', 'language', 'translation', 'tool', ',', 'voice', 'assistant', '.']\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "print(\"\\nLemmatized Words:\")\n",
        "print(lemmatized_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67598711-559a-4943-aa50-207cbbc23035",
      "metadata": {
        "id": "67598711-559a-4943-aa50-207cbbc23035"
      },
      "source": [
        "# 9. Named Entity Recognition(NER) with SpaCy\n",
        "#### TASK 5: NAMED ENTITY RECOGNITION (NER)\n",
        "- NER: Identifies specific entities such as \"NLP\" as an organization.\n",
        "- NER identifies entities like names, dates, and organizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3afaa727-84da-46ae-91f4-8dc40abb35cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3afaa727-84da-46ae-91f4-8dc40abb35cc",
        "outputId": "ffbce987-f3b2-4b43-fa06-54c13de0b4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Named Entities:\n",
            "NLP (ORG)\n",
            "NLP (ORG)\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")  # Load the model using the correct name\n",
        "doc = nlp(text)\n",
        "print(\"\\nNamed Entities:\")\n",
        "for entity in doc.ents:\n",
        "    print(f\"{entity.text} ({entity.label_})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "200ed6a3-3b5a-4649-9f8d-3409ad1ede84",
      "metadata": {
        "id": "200ed6a3-3b5a-4649-9f8d-3409ad1ede84"
      },
      "source": [
        "# 10. Sentiment Analysis with TextBlob\n",
        "#### TASK 6: SENTIMENT ANALYSIS\n",
        "- Sentiment Analysis: Evaluates emotional tone or opinion in the text.\n",
        "- Polarity measures sentiment on a scale of -1 (negative) to +1 (positive).\n",
        "- Subjectivity indicates whether the text is factual (close to 0) or opinionated (close to 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "907ea251-92b6-4887-b4d7-becb32dd299d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "907ea251-92b6-4887-b4d7-becb32dd299d",
        "outputId": "31da0523-35e8-47b7-95d6-b94db43be492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment Analysis:\n",
            "Polarity: 0.04999999999999999, Subjectivity: 0.5875\n",
            "The sample text has a Positive sentiment.\n"
          ]
        }
      ],
      "source": [
        "blob = TextBlob(text)\n",
        "polarity = blob.sentiment.polarity\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "print(\"\\nSentiment Analysis:\")\n",
        "print(f\"Polarity: {polarity}, Subjectivity: {subjectivity}\")\n",
        "\n",
        "# Determine if the text is positive or not\n",
        "if polarity > 0:\n",
        "    print(\"The sample text has a Positive sentiment.\")\n",
        "elif polarity < 0:\n",
        "    print(\"The sample text has a Negative sentiment.\")\n",
        "else:\n",
        "    print(\"The sample text has a Neutral sentiment.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4749767b-8b2e-49e8-a5ca-4f2723aa5741",
      "metadata": {
        "id": "4749767b-8b2e-49e8-a5ca-4f2723aa5741"
      },
      "source": [
        "# *************************************************************************"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fb5bfd-b2b5-41a0-97ed-8e358c1456b0",
      "metadata": {
        "id": "25fb5bfd-b2b5-41a0-97ed-8e358c1456b0"
      },
      "source": [
        "# About Me:-\n",
        "## Name - Aatish Kumar Baitha\n",
        "  - M.Tech(Data Science)\n",
        "- YouTube\n",
        "  - https://www.youtube.com/@EngineeringWithAatish/playlists\n",
        "- My Linkedin Profile\n",
        "  - https://www.linkedin.com/in/aatish-kumar-baitha-ba9523191\n",
        "- My Blog\n",
        "  - https://computersciencedatascience.blogspot.com/\n",
        "- My Github Profile\n",
        "  - https://github.com/Aatishkb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45bbe8c1-e653-4104-86cf-3d6d12479a4d",
      "metadata": {
        "id": "45bbe8c1-e653-4104-86cf-3d6d12479a4d"
      },
      "source": [
        "# Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e856b7c9-63d1-4e96-b4ee-e84e2b868c8a",
      "metadata": {
        "id": "e856b7c9-63d1-4e96-b4ee-e84e2b868c8a"
      },
      "source": [
        "# *************************************************************************"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}